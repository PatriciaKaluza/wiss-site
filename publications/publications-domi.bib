@inproceedings{madoc31534,
         address = {Berlin [u.a.]},
        language = {ARRAY(0x7f1efecb9f08)},
          volume = {7540},
           title = {Does it fit? KOS evaluation using the ICE-Map visualization},
       booktitle = {The Semantic Web: ESWC 2012 Satellite Events : revised selected papers / ESWC 2012 Satellite Events, Heraklion, Crete, Greece, May 27 - 31, 2012},
       publisher = {Springer},
         journal = {Lecture Notes in Computer Science},
            year = {2015},
          author = {Kai Eckert and Dominique Ritze and Magnus Pfeffer},
           pages = {408--412},
        abstract = {The ICE-Map Visualization was developed to graphically analyze the distribution of indexing results within a given Knowledge Organization System (KOS) hierarchy and allows the user to explore the document sets and the KOSs at the same time. In this paper, we demonstrate the use of the ICE-Map Visualization in combination with a simple automatic indexer to visualize the semantic overlap between a KOS and a set of documents.},
             url = {https://madoc.bib.uni-mannheim.de/31534/}
}

@article{madoc39947,
         address = {Amsterdam [u.a.]},
        language = {ARRAY(0x7f1efedff068)},
          number = {3},
           title = {The Mannheim Search Join Engine},
          volume = {35},
       publisher = {Elsevier},
         journal = {Web semantics : science, services and agents on the World Wide Web },
            year = {2015},
          author = {Oliver Lehmberg and Dominique Ritze and Petar Ristoski and Robert Meusel and Heiko Paulheim and Christian Bizer},
           pages = {159--166},
             url = {https://madoc.bib.uni-mannheim.de/39947/},
        abstract = {A Search Join is a join operation which extends a user-provided table with additional attributes based on a large corpus of heterogeneous data originating from the Web or corporate intranets. Search Joins are useful within a wide range of application scenarios: Imagine you are an analyst having a local table describing companies and you want to extend this table with attributes containing the headquarters, turnover, and revenue of each company. Or imagine you are a film enthusiast and want to extend a table describing films with attributes like director, genre, and release date of each film. This article presents the Mannheim Search Join Engine which automatically performs such table extension operations based on a large corpus of Web data. Given a local table, the Mannheim Search Join Engine searches the corpus for additional data describing the entities contained in the input table. The discovered data are joined with the local table and are consolidated using schema matching and data fusion techniques. As a result, the user is presented with an extended table and given the opportunity to examine the provenance of the added data. We evaluate the Mannheim Search Join Engine using heterogeneous data originating from over one million different websites. The data corpus consists of HTML tables, as well as Linked Data and Microdata annotations which are converted into tabular form. Our experiments show that the Mannheim Search Join Engine achieves a coverage close to 100\% and a precision of around 90\% for the tasks of extending tables describing cities, companies, countries, drugs, books, films, and songs.}
}

@inproceedings{madoc39487,
       booktitle = {Proceedings of the 5th International Conference on Web Intelligence, Mining and Semantics, WIMS 2015, Larnaca, Cyprus, July 13-15, 2015},
           title = {Matching HTML Tables to DBpedia},
       publisher = {ACM},
         address = {New York, NY},
        language = {ARRAY(0x7f1efec691b0)},
            year = {2015},
          author = {Dominique Ritze and Oliver Lehmberg and Christian Bizer},
           pages = {Paper 10:1--10:6},
          series = {WIMS '15},
        abstract = {Millions of HTML tables containing structured data can be found on the Web. With their wide coverage, these tables are potentially very useful for filling missing values and extending cross-domain knowledge bases such as DBpedia, YAGO, or the Google Knowledge Graph. As a prerequisite for being able to use table data for knowledge base extension, the HTML tables need to be matched with the knowledge base, meaning that correspondences between table rows/columns and entities/schema elements of the knowledge base need to be found. This paper presents the T2D gold standard for measuring and comparing the performance of HTML table to knowledge base matching systems. T2D consists of 8 700 schema-level and 26 100 entity-level correspondences between the WebDataCommons Web Tables Corpus and the DBpedia knowledge base. In contrast related work on HTML table to knowledge base matching, the Web Tables Corpus (147 million tables), the knowledge base, as well as the gold standard are publicly available. The gold standard is used afterward to evaluate the performance of T2K Match, an iterative matching method which combines schema and instance matching. T2K Match is designed for the use case of matching large quantities of mostly small and narrow HTML tables against large cross-domain knowledge bases. The evaluation using the T2D gold standard shows that T2K Match discovers table-to-class correspondences with a precision of 94\%, row-to-entity correspondences with a precision of 90\%, and column-to-property correspondences with a precision of 77\%.},
             url = {https://madoc.bib.uni-mannheim.de/39487/}
}

@inproceedings{madoc40114,
          author = {Cheng Xie and Dominique Ritze and Blerina Spahiu and Cai Hongming},
            year = {2015},
           pages = {222--223},
         journal = {CEUR workshop proceedings},
           title = {Instance-based property matching in linked open data environment},
          volume = {1545},
       booktitle = {OM 2015 :  Proceedings of the 10th International Workshop on Ontology Matching collocated with the 14th International Semantic Web Conference (ISWC 2015) Bethlehem, PA, USA, October 12, 2015},
       publisher = {RWTH},
         address = {Aachen},
        language = {ARRAY(0x7f1efedb21b0)},
             url = {https://madoc.bib.uni-mannheim.de/40114/}
}

@inproceedings{madoc36768,
         address = {Gent},
        language = {ARRAY(0x7f1efec6c1b0)},
           title = {DEMO: A Lightweight Provenance Pingback and Query Service for Web Publications},
            note = {Online Ressource},
       booktitle = {IPAW 2014: 5th International Provenance and Annotation Workshop : June 9-13, 2014, Cologne, Germany},
       publisher = {UGent Institutional Repository},
            year = {2014},
          author = {Tom De Nies and Robert Meusel and Dominique Ritze and Kai Eckert and Anastasia Dimou and Laurens De Vocht and Ruben Verborgh and Erik Mannens and Rik Van de Walle},
           pages = {1--6},
             url = {https://madoc.bib.uni-mannheim.de/36768/},
        abstract = {Web resources, such as publications, datasets, pictures and
others can be directly linked to their provenance data, as described in
the specification about Provenance Access and Query (PROV-AQ) by
the W3C. On its own, this approach places all responsibility with the
publisher of the resource, who hopefully maintains and publishes provenance
information. In reality, however, most publishers lack incentives to
publish the provenance of resources, even if the owner would like such
information to be published. Currently, it is very intricate to link existing
resources to new provenance information, either provided by the
owner or a third party. In this paper, we present a solution for this problem
by implementing a lightweight, read/write provenance query service,
integrated with a pingback mechanism, following the PROV-AQ recommendation.}
}

@inproceedings{madoc37369,
         journal = {CEUR Workshop Proceedings},
           pages = {61--104},
            year = {2014},
          author = {Zlatan Dragisic and Kai Eckert and J{\'e}r{\^o}me Euzenat and Daniel Faria and Alfio Ferrara and Roger Granada and Valentina Ivanova and Ernesto Jim{\'e}nez-Ruiz and Andreas Oskar Kempf and Patrick Lambrix and Stefano Montanelli and Heiko Paulheim and Dominique Ritze and Pavel Shvaiko and Alessandro Solimando and C{\'a}ssia Trojahn and Ondrej Zamazal and Bernardo Cuenca Grau},
        language = {ARRAY(0x7f1efede34b8)},
         address = {Aachen},
       publisher = {RWTH},
       booktitle = {OM 2014 : Proceedings of the 9th International Workshop on Ontology Matching co-located with the 13th International Semantic Web Conference (ISWC 2014) ; Riva del Garda, Trentino, Italy, October 20, 2014},
          volume = {1317},
           title = {Results of the Ontology Alignment Evaluation Initiative 2014},
             url = {https://madoc.bib.uni-mannheim.de/37369/}
}

@inproceedings{madoc35940,
           pages = {259--260},
            year = {2014},
          author = {Kai Eckert and Dominique Ritze and Konstantin Baierer and Christian Bizer},
        language = {ARRAY(0x7f1efecd9cb8)},
         address = {New York, NY},
       publisher = {ACM},
           title = {RESTful Open Workflows for Data Provenance and Reuse},
       booktitle = {23rd International World Wide Web Conference, WWW '14, Seoul, Republic of Korea, April 7-11, 2014, Companion Volume},
             url = {https://madoc.bib.uni-mannheim.de/35940/}
}

@article{madoc35425,
           title = {New Ways of Mapping Knowledge Organization Systems: Using a Semi-Automatic Matching Procedure for Building up Vocabulary Crosswalks},
          volume = {41},
       publisher = {Ergon-Verl.},
          number = {1},
         address = {W{\"u}rzburg},
        language = {ARRAY(0x7f1efedb1bf8)},
          author = {Andreas Oskar Kempf and Dominique Ritze and Kai Eckert and Benjamin Zapilko},
            year = {2014},
           pages = {66--75},
         journal = {Knowledge Organization : KO},
             url = {https://madoc.bib.uni-mannheim.de/35425/}
}

@misc{madoc37371,
          author = {Oliver Lehmberg and Dominique Ritze and Petar Ristoski and Kai Eckert and Heiko Paulheim and Christian Bizer},
            year = {2014},
           title = {Extending Tables with Data from over a Million
Websites},
         address = {[Karlsruhe] [u.a.]},
        language = {ARRAY(0x7f1efecb9c80)},
         journal = {Semantic Web Challenge 2014},
             url = {https://madoc.bib.uni-mannheim.de/37371/}
}

@incollection{madoc35281,
       publisher = {Springer},
           title = {Data Enrichment in Discovery Systems Using Linked Data},
           pages = {455--462},
          author = {Dominique Ritze and Kai Eckert},
            year = {2014},
        language = {ARRAY(0x7f1efece68a0)},
         address = {Cham [u.a.]},
             url = {https://madoc.bib.uni-mannheim.de/35281/}
}

@inproceedings{madoc36747,
          author = {Dominique Ritze and C{\"a}cilia Zirn and Colin Greenstreet and Kai Eckert and Simone Paolo Ponzetto},
            year = {2014},
           pages = {26--30},
         address = {Reykjavik},
        language = {ARRAY(0x7f1efede2c78)},
            note = {Online Ressource},
           title = {Named Entities in Court: The MarineLives Corpus},
       booktitle = {Language Resources and Technologies for Processing and Linking Historical Documents and Archives - Deploying Linked Open Data in Cultural Heritage  Workshop : associated with the LREC 2014 Conference, 26 - 30 May 2014, Reykjavik},
       publisher = {LREC},
             url = {https://madoc.bib.uni-mannheim.de/36747/}
}

@incollection{madoc37370,
           title = {State-of-the-Art in Multilingual and Cross-Lingual Ontology Matching},
       publisher = {Springer},
            year = {2014},
          author = {C{\'a}ssia Trojahn and Bo Fu and Ondrej Zamazal and Dominique Ritze},
           pages = {119--135},
         address = {Berlin [u.a.]},
        language = {ARRAY(0x7f1efed08a98)},
             url = {https://madoc.bib.uni-mannheim.de/37370/}
}

@misc{madoc35978,
       publisher = {RWTH},
           title = {WaSABi 2013 Semantic Web Enterprise Adoption and Best Practice : Proceedings of the Workshop on Semantic Web Enterprise Adoption and Best Practice Co-located with 12th International Semantic Web Conference (ISWC 2013), Sydney, Australia, October 22, 2013},
          volume = {1106},
        language = {ARRAY(0x7f1efed8aa90)},
         address = {Aachen},
          editor = {Sam Coppens and Karl Hammer and Magnus Knuth and Marco Neumann and Dominique Ritze and Harald Sack and Miel Vander Sande},
            year = {2013},
         journal = {CEUR workshop proceedings},
             url = {https://madoc.bib.uni-mannheim.de/35978/}
}

@inproceedings{madoc35225,
        language = {ARRAY(0x7f1efec9f7a0)},
         address = {Aachen},
       publisher = {RWTH},
           title = {Results of the Ontolog Alignment Evaluation Initiative 2013},
          volume = {1111},
       booktitle = { Proceedings of the 8th International Workshop on Ontology Matching co-located with the 12th International Semantic Web Conference (ISWC 2013) Sydney, Australia, October 21, 2013},
         journal = {CEUR workshop proceedings},
           pages = {61--100},
            year = {2013},
          author = {Bernardo Cucena Grau and Zlatan Dragisic and Kai Eckert and J{\'e}r{\^o}me Euzenat and Alfio Ferrara and Roger Granada and Valentina Ivanova and Ernesto Jim{\'e}nez-Ruiz and Andreas Oskar Kempf and Patrick Lambrix and Andriy Nikolov and Heiko Paulheim and Dominique Ritze and Francois Scharffe and Pavel Shvaiko and C{\'a}ssia Trojahn and Ondrej Zamazal},
             url = {https://madoc.bib.uni-mannheim.de/35225/},
        abstract = {Ontology matching consists of finding correspondences between se-
mantically related entities of two ontologies. OAEI campaigns aim at comparing
ontology matching systems on precisely defined test cases. These test cases can
use ontologies of different nature (from simple thesauri to expressive OWL on-
tologies) and use different modalities, e.g., blind evaluation, open evaluation and
consensus. OAEI 2013 offered 6 tracks with 8 test cases followed by 23 partici-
pants. Since 2010, the campaign has been using a new evaluation modality which
provides more automation to the evaluation. This paper is an overall presentation
of the OAEI 2013 campaign.}
}

@inproceedings{madoc33363,
       booktitle = {The semantic web : semantics and big data ; 10th international conference ; proceedings / ESWC 2013},
          volume = {7882},
           title = {Towards Evaluating Interactive Ontology Matching Tools},
       publisher = {Springer},
         address = {Berlin [u.a.]},
        language = {ARRAY(0x7f1efec84b08)},
          author = {Heiko Paulheim and Sven Hertling and Dominique Ritze},
            year = {2013},
           pages = {31--45},
         journal = {Lecture Notes in Computer Science},
             url = {https://madoc.bib.uni-mannheim.de/33363/}
}

@inproceedings{madoc33845,
           pages = {35--40},
          author = {Dominique Ritze and Katarina Boland},
            year = {2013},
         journal = {Proceedings of the International Conference on Dublin Core and Metadata Applications},
       publisher = {Dublin Core Metadata Initiative},
           title = {Integration of Research Data and Research Data Links into Library Catalogues},
       booktitle = {DC-2013 - The Lisbon Proceedings : Papers, Project Reports and Posters for DC-2013 in Lisbon, Portugal, 2-6 September 2013},
            note = {Online Ressource},
        language = {ARRAY(0x7f1efed3da58)},
         address = {Dublin, Ohio},
             url = {https://madoc.bib.uni-mannheim.de/33845/}
}

@incollection{madoc34366,
         journal = {Bibliotheks- und Informationspraxis},
           pages = {122--138},
            year = {2013},
          author = {Dominique Ritze and Kai Eckert and Magnus Pfeffer},
        language = {ARRAY(0x7f1efed7b410)},
         address = {Berlin},
       publisher = {De Gruyter Saur},
          volume = {50},
           title = {Forschungsdaten},
             url = {https://madoc.bib.uni-mannheim.de/34366/}
}

@inproceedings{madoc33828,
         address = {Berlin [u.a.]},
        language = {ARRAY(0x7f1efeddbd50)},
       booktitle = {	 The Semantic Web ? ISWC 2013 : 12th International Semantic Web Conference, Sydney, NSW, Australia, October 21-25, 2013, Proceedings, Part II},
          volume = {8219},
           title = {Evaluation measures for ontology matchers in supervised matching scenarios},
       publisher = {Springer},
         journal = {Lecture Notes in Computer Science},
            year = {2013},
          author = {Dominique Ritze and Heiko Paulheim and Kai Eckert},
           pages = {392--407},
             url = {https://madoc.bib.uni-mannheim.de/33828/}
}

@inproceedings{madoc33333,
         journal = {CEUR workshop proceedings},
            year = {2012},
          author = {Jos{\'e} Luis Aguirre and Kai Eckert and J{\'e}r{\^o}me Euzenat and Alfio Ferrara and Willem Robert van Hage and Laura Hollink and Christian Meilicke and Andriy Nikolov and Dominique Ritze and Francois Scharffe and Pavel Shvaiko and Ondrej Svab-Zamazal and C{\'a}ssia Trojahn and Ernesto Jim{\'e}nez-Ruiz and Bernardo Cuenca Grau and Benjamin Zapilko},
           pages = {1--43},
         address = {Aachen},
        language = {ARRAY(0x7f1efed22150)},
          volume = {946},
       booktitle = {OM-2012 Ontology Matching : Proceedings of the 7th International Workshop on Ontology Matching (OM-2012) collocated with the 11th International Semantic Web Conference (ISWC-2012) Boston, MA, USA, November 11, 2012},
           title = {Results of the Ontology Alignment Evaluation Initiative 2012},
       publisher = {RWTH},
             url = {https://madoc.bib.uni-mannheim.de/33333/}
}

@inproceedings{madoc32554,
           pages = {150--161},
            year = {2012},
          author = {Katarina Boland and Dominique Ritze and Kai Eckert and Brigitte Mathiak},
         journal = {Lecture Notes in Computer Science},
       publisher = {Springer},
          volume = {7489},
           title = {Identifying References to Datasets in Publications},
       booktitle = {Theory and Practice of Digital Libraries : Second International Conference, TPDL 2012, Paphos, Cyprus, September 23-27, 2012. Proceedings},
        language = {ARRAY(0x7f1efed44df8)},
         address = {Berlin [u.a.]},
             url = {https://madoc.bib.uni-mannheim.de/32554/},
        abstract = {Research data and publications are usually stored in separate
and structurally distinct information systems. Often, links between these
resources are not explicitly available which complicates the search for
previous research. In this paper, we propose a pattern induction method
for the detection of study references in full texts. Since these references
are not specified in a standardized way and may occur inside a variety of
different contexts ? i.e., captions, footnotes, or continuous text ? our algo-rithm is required to induce very flexible patterns. To overcome the sparse
distribution of training instances, we induce patterns iteratively using a
bootstrapping approach. We show that our method achieves promising
results for the automatic identification of data references and is a first
step towards building an integrated information system}
}

@inproceedings{madoc33343,
          volume = {843},
       booktitle = {IWEST 2012 :  Proceedings of the Second International Workshop on Evaluation of Semantic Technologies (IWEST 2012), Workshop at the 9th Extended Semantic Web Conference (ESWC2012) Heraklion, Greece, May 28, 2012},
           title = {Multilingual ontology matching evaluation - a first report on using multifarm},
       publisher = {RWTH},
         address = {Aachen},
        language = {ARRAY(0x7f1efed21fa0)},
          author = {Christian Meilicke and C{\'a}ssia Trojahn and Ondrej Svab-Zamazal and Dominique Ritze},
            year = {2012},
           pages = {1--12},
         journal = {CEUR workshop proceedings},
             url = {https://madoc.bib.uni-mannheim.de/33343/}
}

@inproceedings{madoc32996,
           pages = {107--118},
          author = {Dominique Ritze and Kai Eckert},
            year = {2012},
         journal = {Schriften des Forschungszentrums J{\"u}lich / Reihe Bibliothek},
       publisher = {Forschungszentrum J{\"u}lich},
       booktitle = {Vernetztes Wissen ? Daten, Menschen, Systeme : 6. Konferenz der Zentralbibliothek Forschungszentrum J{\"u}lich; 5. - 7. November 2012; Proceedingsband},
          volume = {21},
           title = {Linked Data als Infrastruktur zur Integration von Forschungsdaten und Publikationen},
        language = {ARRAY(0x7f1efecb2a08)},
         address = {J{\"u}lich},
        abstract = {Die fehlende Integration von Publikationen und Forschungsdaten erschwert zum 
einen die wissenschaftliche Recherche und behindert zum anderen sowohl die 
Nachweisbarkeit als auch die Reproduzierbarkeit von Ergebnissen. Die 
Verkn{\"u}pfungen zwischen Forschungsdaten und Publikationen werden u.a. derzeit im 
DFG-gef{\"o}rderten Projekt InFoLiS von der UB Mannheim in Kooperation mit der 
GESIS und dem Lehrstuhl f{\"u}r K{\"u}nstliche Intelligenz der Universit{\"a}t Mannheim 
erstellt. 
Die so gefundenen Verkn{\"u}pfungen m{\"u}ssen in geeigneter Weise zur Verf{\"u}gung 
gestellt werden, so dass sie in den vorhandenen Recherchesystemen genutzt 
werden k{\"o}nnen. Dazu bietet sich eine Repr{\"a}sentation als Linked Data an. 
In diesem Paper beschreiben wir die M{\"o}glichkeiten, solcherart zur Verf{\"u}gung 
gestellte Daten in das eigene Recherchesystem zu integrieren. Wir unterscheiden 
server- und clientseitige Anreicherungen und zeigen die jeweiligen Vor- und 
Nachteile. Dabei gehen wir insbesondere auf die clientseitige Anreicherung ein, die 
minimal-invasiv umgesetzt werden kann und nur einen geringen Aufwand bedeutet. 
Des Weiteren zeigen wir, dass sich auch damit alle Anforderungen, die sich in 
unserem konkreten Anwendungsfall ergeben, erf{\"u}llen lassen. },
             url = {https://madoc.bib.uni-mannheim.de/32996/}
}

@inproceedings{madoc33322,
         address = {Aachen},
        language = {ARRAY(0x7f1efecd8508)},
          volume = {946},
       booktitle = {OM-2012 Ontology Matching : Proceedings of the 7th International Workshop on Ontology Matching (OM-2012) collocated with the 11th International Semantic Web Conference (ISWC-2012), Boston, MA, USA, November 11, 2012},
           title = {Thesaurus mapping: a challenge for ontology alignment?},
       publisher = {RWTH},
         journal = {CEUR Workshop Proceedings},
            year = {2012},
          author = {Dominique Ritze and Kai Eckert},
             url = {https://madoc.bib.uni-mannheim.de/33322/}
}

@inproceedings{madoc31960,
        language = {ARRAY(0x7f1efedf0bb8)},
         address = {Aachen},
       publisher = {RWTH},
          volume = {814},
       booktitle = {Proceedings of the 6th International Workshop on Ontology Matching (OM-2011)},
           title = {Towards an Automatic Parameterization of Ontology
Matching Tools based on Example Mappings},
         journal = {CEUR Workshop Proceedings},
           pages = {Paper 4},
          author = {Dominique Ritze and Heiko Paulheim},
            year = {2011},
             url = {https://madoc.bib.uni-mannheim.de/31960/},
        abstract = {With a growing number of ontologies and datasets using those ontologies, ontology mappings become an essential building block of the Semantic
Web. In the last years, a larger number of sophisticated ontology matching tools
for generating such mappings has been developed. The quality of the mappings
provided by those tools typically depends on the settings of the tools? parameters. As this is a non-trivial task for an end user, we propose the ECOMatch
approach, which asks the user to provide example mappings instead of parameter settings, and automatically determines a suitable parameter setting based on
those examples. We show how the preliminary result quality of ontology mappings can be improved by applying automatic, example-based con?guration of
ontology matching tools.}
}

@inproceedings{madoc32129,
       publisher = {RWTH},
       booktitle = {OM-2010 :  Proceedings of the 5th International Workshop on Ontology Matching (OM-2010) collocated with the 9th International Semantic Web Conference (ISWC-2010), Shanghai, China, November 7, 2010},
          volume = {689},
           title = {Linguistic Analysis for Complex Ontology Matching},
        language = {ARRAY(0x7f1efecaaf40)},
         address = {Aachen},
           pages = {Paper 1},
            year = {2010},
          author = {Dominique Ritze and Johanna V{\"o}lker and Christian Meilicke and Ondrej Svab-Zamazal},
         journal = {CEUR Workshop Proceedings},
             url = {https://madoc.bib.uni-mannheim.de/32129/}
}

@misc{madoc26380,
       publisher = {RWTH},
           title = {A pattern-based ontology matching approach for detecting complex correspondences},
        language = {ARRAY(0x7f1efed74330)},
         address = {Aachen},
           month = {?},
            year = {2009},
          author = {Dominique Ritze and Christian Meilicke and Ondrej Svab-Zamazal and Heiner Stuckenschmidt},
         journal = {Proceedings of the 4th International Workshop on Ontology Matching (OM-2009) : collocated with the 8th International Semantic Web Conference (ISWC-2009) Chantilly, USA, October 25, 2009},
          series = {CEUR Workshop Proceedings ; 551. Online: http://ceur-ws.org/Vol-551/om2009\_Tpaper3.pdf},
             url = {https://madoc.bib.uni-mannheim.de/26380/}
}

